{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210217_7기_고급시각저녁",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caxcmnFaTW8N"
      },
      "source": [
        "# [ICTCOG AI Academy] 7기 고급시각저녁반\r\n",
        "# Tensorflow를 활용한 기계학습/딥러닝 (3)\r\n",
        "\r\n",
        "- binary class 이진 분류 \r\n",
        "  - 2개인 경우 1개의 클래스로 분류\r\n",
        "- multiclass 다중 분류\r\n",
        "  - 3 개 이상인 경우 1개의 클래스로 분류\r\n",
        "- multi label/output\r\n",
        "  - 동시에 두개 이상으로 예측\r\n",
        "- mult task\r\n",
        "\r\n",
        "\r\n",
        "- regression은 classification에 활용 할 수 있다 \r\n",
        "  - 아날로그 연속값 vs 디지털 이산값\r\n",
        "    - 연속값을 쪼개면 이산값처럼 사용 가능\r\n",
        "  \r\n",
        "> - 신경망은 태생적으로 classification\r\n",
        "  - 마지막 레이어의 유닛의 갯수에 따라 분류 가능 \r\n",
        "\r\n",
        " [Scikit-learn multiclass 참고](https://scikit-learn.org/stable/modules/multiclass.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQO80rNTS7Z"
      },
      "source": [
        "from sklearn.datasets import load_boston, load_iris  #regression, classification"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L6PrOv_YVEI",
        "outputId": "92637be9-23f4-41fd-996f-a22fcafba384"
      },
      "source": [
        "data=load_boston()\r\n",
        "data.data.shape # X 506x13"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBP9KvoCZlg0",
        "outputId": "7b9a1c5b-cd26-4157-9191-a2cbb45c09b3"
      },
      "source": [
        "data.target    # y값 - boston 집값"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm8vSfnWYX1-",
        "outputId": "d745ce30-661f-4d36-9f39-85a64c2f0afe"
      },
      "source": [
        "data1=load_iris()\r\n",
        "data1.data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8oAMdt_Yhyf"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CoXMvYNYtC6"
      },
      "source": [
        "### tf.keras.models.Sequential\r\n",
        "- keras 사용하는 3번째 유형\r\n",
        "- 모델 자체는 합성함수\r\n",
        "\r\n",
        "> 함수형 패러다임\r\n",
        "  1. 함수 선언/정의\r\n",
        "  2. 조합 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T65fZWJaZWT"
      },
      "source": [
        "#### activation function 활성함수\r\n",
        "- 딥러닝 성능 좋은 이유\r\n",
        "- **비선형 함수**를 사용해서 선형 분리 가능하도록 데이터 공간 왜곡\r\n",
        "  - 선형 모델은 XOR문제 해결 불가\r\n",
        "- 레이어가 깊어질 수록 gradient vanishing 으로 인한 underfitting\r\n",
        "[Colah's blog post](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)\r\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX5pKruveHWy"
      },
      "source": [
        "#### argument 테크닉 3가지\r\n",
        "1. 문자열\r\n",
        "  - 디폴트 값 사용\r\n",
        "2. 함수\r\n",
        "  - 디폴트 값 바꾸기 가능\r\n",
        "  - decorator \r\n",
        "3. 객체\r\n",
        "\r\n",
        "> 3가지 방식 지원하지 않는 경우가 있음 \r\n",
        "  - acativation 은 문자열, 함수만 존재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLD8OgAmfWQC",
        "outputId": "4a9421ef-2052-4a88-abd0-fffd1b9f0bdf"
      },
      "source": [
        "tf.keras.activations.relu"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.keras.activations.relu>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV-AZw1bfx0d",
        "outputId": "658f8130-ea61-44c9-aa23-ce21b1fd835b"
      },
      "source": [
        "from functools import partial   \r\n",
        "#함수형 패러다임\r\n",
        "relu_v2= partial(tf.keras.activations.relu, alpha=1) #기본 값 변경\r\n",
        "relu_v2"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functools.partial(<function relu at 0x7f6fce37d048>, alpha=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHsSwAlJdiDr",
        "outputId": "491ebb81-b0d8-49d1-9923-ed8bd6f4b328"
      },
      "source": [
        "#인자 테크닉\r\n",
        "tf.keras.layers.Dense( 16 ,activation='relu')           #활성 함수 지정\r\n",
        "tf.keras.layers.Dense( 16 ,activation= tf.keras.activations.relu) #함수 \r\n",
        "tf.keras.layers.Dense( 16 ,activation= tf.nn.relu)      #함수 텐서플로우의 relu\r\n",
        "tf.keras.layers.Activation('relu')                      #클래스 -> 레이어 개념으로 사용\r\n",
        "\r\n",
        "'binarycrossentropy'                 #문자열\r\n",
        "tf.keras.losses.binary_crossentropy  #함수\r\n",
        "tf.keras.losses.BinaryCrossentropy   #클래스"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.losses.BinaryCrossentropy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJm4gSu0iKpF"
      },
      "source": [
        "#### keras의 laeyrs는 2가지\r\n",
        "#### 1. 이론\r\n",
        "- activation 전후로 다른 것을 넣고자 할때\r\n",
        "  - eg. batch normalization from ResNet\r\n",
        ">  `tf.keras.layers.Dense(16), \r\n",
        ">  tf.keras.layers.BatchNormalization(),\r\n",
        ">  tf.keras.layers.Activation('relu')`\r\n",
        "\r\n",
        "#### 2. 구현 편의성\r\n",
        "> `tf.keras.layers.Dense(16, input_shape=(13,),activation='relu')`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7bFmxemYsMc"
      },
      "source": [
        "# 3 layers/ 2 hidden layers\r\n",
        "model_boston= tf.keras.models.Sequential([\r\n",
        "                            tf.keras.layers.Dense(16, input_shape=(13,),activation='relu') , #문자열\r\n",
        "                            tf.keras.layers.Dense(16),           #함수\r\n",
        "                            tf.keras.layers.Activation('relu'),  #클래스\r\n",
        "                            tf.keras.layers.Dense(1 )            #regression-> output 1개 (변형x)\r\n",
        "\r\n",
        "])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEbeEnAVZ42Z",
        "outputId": "3a8f60df-be79-432d-e0b5-ebd6e7e85e48"
      },
      "source": [
        "model_boston.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 16)                224       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi6M1nAoaNap",
        "outputId": "cbbb928d-af3b-4fa0-f2e0-ad724ed94f70"
      },
      "source": [
        "model_boston.compile(loss='mse')                         #compile 학습 전략\r\n",
        "model_boston.fit(boston.data, boston.target , epochs=2 ) #fit 학습"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 1898.2325\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 367.2814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fc36526a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWACVcvgg2uR"
      },
      "source": [
        "각 레이어 별로 activation function\r\n",
        "마지막 output\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs8qDDe3fGj8",
        "outputId": "8b9aab86-5409-4c3e-a3b1-f0d6fa24e022"
      },
      "source": [
        "model_boston(boston.data)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(506, 1), dtype=float32, numpy=\n",
              "array([[ 17.019976  ],\n",
              "       [ 16.600845  ],\n",
              "       [ 15.282056  ],\n",
              "       [ 13.260794  ],\n",
              "       [ 13.128686  ],\n",
              "       [ 13.147584  ],\n",
              "       [ 19.108627  ],\n",
              "       [ 19.167967  ],\n",
              "       [ 19.458279  ],\n",
              "       [ 19.097897  ],\n",
              "       [ 19.225563  ],\n",
              "       [ 19.118023  ],\n",
              "       [ 19.094635  ],\n",
              "       [ 19.25844   ],\n",
              "       [ 18.557377  ],\n",
              "       [ 19.264168  ],\n",
              "       [ 18.453354  ],\n",
              "       [ 18.934023  ],\n",
              "       [ 16.816395  ],\n",
              "       [ 18.938581  ],\n",
              "       [ 18.631004  ],\n",
              "       [ 18.869068  ],\n",
              "       [ 19.139076  ],\n",
              "       [ 19.096394  ],\n",
              "       [ 19.082632  ],\n",
              "       [ 17.534914  ],\n",
              "       [ 18.694183  ],\n",
              "       [ 17.738602  ],\n",
              "       [ 18.722172  ],\n",
              "       [ 18.49425   ],\n",
              "       [ 18.463448  ],\n",
              "       [ 18.252064  ],\n",
              "       [ 21.728382  ],\n",
              "       [ 18.086077  ],\n",
              "       [ 21.798016  ],\n",
              "       [ 17.690811  ],\n",
              "       [ 17.53206   ],\n",
              "       [ 16.20176   ],\n",
              "       [ 15.544013  ],\n",
              "       [ 14.276149  ],\n",
              "       [ 13.740951  ],\n",
              "       [ 14.639618  ],\n",
              "       [ 14.542748  ],\n",
              "       [ 15.034114  ],\n",
              "       [ 14.181255  ],\n",
              "       [ 14.204035  ],\n",
              "       [ 14.341413  ],\n",
              "       [ 17.481678  ],\n",
              "       [ 18.754257  ],\n",
              "       [ 15.863881  ],\n",
              "       [ 15.800608  ],\n",
              "       [ 16.6236    ],\n",
              "       [ 14.650714  ],\n",
              "       [ 14.737378  ],\n",
              "       [ 22.456142  ],\n",
              "       [ 15.230962  ],\n",
              "       [ 20.77695   ],\n",
              "       [ 17.790575  ],\n",
              "       [ 18.251484  ],\n",
              "       [ 18.984497  ],\n",
              "       [ 19.985191  ],\n",
              "       [ 19.138647  ],\n",
              "       [ 19.652     ],\n",
              "       [ 19.207335  ],\n",
              "       [ 14.793504  ],\n",
              "       [ 19.868345  ],\n",
              "       [ 21.179089  ],\n",
              "       [ 20.208885  ],\n",
              "       [ 20.53011   ],\n",
              "       [ 20.289856  ],\n",
              "       [ 17.03511   ],\n",
              "       [ 18.855263  ],\n",
              "       [ 16.814342  ],\n",
              "       [ 17.209904  ],\n",
              "       [ 20.353481  ],\n",
              "       [ 20.605495  ],\n",
              "       [ 20.081017  ],\n",
              "       [ 20.700132  ],\n",
              "       [ 20.945444  ],\n",
              "       [ 20.929794  ],\n",
              "       [ 16.955921  ],\n",
              "       [ 19.155823  ],\n",
              "       [ 16.983576  ],\n",
              "       [ 18.145329  ],\n",
              "       [ 14.415446  ],\n",
              "       [ 14.712615  ],\n",
              "       [ 14.377967  ],\n",
              "       [ 14.534639  ],\n",
              "       [ 16.579391  ],\n",
              "       [ 15.445609  ],\n",
              "       [ 15.875323  ],\n",
              "       [ 16.258858  ],\n",
              "       [ 20.059341  ],\n",
              "       [ 16.543818  ],\n",
              "       [ 20.979452  ],\n",
              "       [ 16.05202   ],\n",
              "       [ 16.716553  ],\n",
              "       [ 16.399475  ],\n",
              "       [ 13.917668  ],\n",
              "       [ 15.735629  ],\n",
              "       [ 19.407455  ],\n",
              "       [ 19.475601  ],\n",
              "       [ 19.421768  ],\n",
              "       [ 19.50679   ],\n",
              "       [ 19.305744  ],\n",
              "       [ 19.402264  ],\n",
              "       [ 19.643757  ],\n",
              "       [ 19.267048  ],\n",
              "       [ 19.262815  ],\n",
              "       [ 19.431854  ],\n",
              "       [ 19.935469  ],\n",
              "       [ 19.26043   ],\n",
              "       [ 19.423103  ],\n",
              "       [ 19.562252  ],\n",
              "       [ 18.738564  ],\n",
              "       [ 18.382423  ],\n",
              "       [ 19.590832  ],\n",
              "       [ 19.26667   ],\n",
              "       [ 17.816397  ],\n",
              "       [ 19.863104  ],\n",
              "       [ 18.383516  ],\n",
              "       [ 19.633286  ],\n",
              "       [ 20.378483  ],\n",
              "       [ 20.753681  ],\n",
              "       [ 20.452541  ],\n",
              "       [ 19.578049  ],\n",
              "       [ 20.524677  ],\n",
              "       [ 22.223698  ],\n",
              "       [ 22.189642  ],\n",
              "       [ 22.56142   ],\n",
              "       [ 21.929008  ],\n",
              "       [ 21.917707  ],\n",
              "       [ 21.315298  ],\n",
              "       [ 22.033688  ],\n",
              "       [ 25.502975  ],\n",
              "       [ 22.259277  ],\n",
              "       [ 21.482134  ],\n",
              "       [ 21.9735    ],\n",
              "       [ 22.460789  ],\n",
              "       [ 22.413218  ],\n",
              "       [ 22.535095  ],\n",
              "       [ 23.528704  ],\n",
              "       [ 20.892948  ],\n",
              "       [ 20.666697  ],\n",
              "       [ 21.08461   ],\n",
              "       [ 27.39384   ],\n",
              "       [ 26.927692  ],\n",
              "       [ 21.070032  ],\n",
              "       [ 19.078585  ],\n",
              "       [ 17.984728  ],\n",
              "       [ 18.818642  ],\n",
              "       [ 17.539038  ],\n",
              "       [ 17.566023  ],\n",
              "       [ 20.154617  ],\n",
              "       [ 18.111567  ],\n",
              "       [ 20.896286  ],\n",
              "       [ 20.490181  ],\n",
              "       [ 17.593666  ],\n",
              "       [ 17.16446   ],\n",
              "       [ 17.745476  ],\n",
              "       [ 16.43629   ],\n",
              "       [ 18.076073  ],\n",
              "       [ 18.822248  ],\n",
              "       [ 19.028637  ],\n",
              "       [ 20.215143  ],\n",
              "       [ 20.487156  ],\n",
              "       [ 17.66817   ],\n",
              "       [ 20.58318   ],\n",
              "       [ 18.436775  ],\n",
              "       [ 17.30276   ],\n",
              "       [ 19.26433   ],\n",
              "       [ 17.310867  ],\n",
              "       [ 16.908443  ],\n",
              "       [ 16.624157  ],\n",
              "       [ 16.843815  ],\n",
              "       [ 14.663329  ],\n",
              "       [ 16.209602  ],\n",
              "       [ 16.79845   ],\n",
              "       [ 16.588894  ],\n",
              "       [ 12.283254  ],\n",
              "       [ 11.487028  ],\n",
              "       [ 12.263987  ],\n",
              "       [ 11.856897  ],\n",
              "       [ 12.0829115 ],\n",
              "       [ 12.606903  ],\n",
              "       [ 12.127262  ],\n",
              "       [ 12.377564  ],\n",
              "       [ 19.096685  ],\n",
              "       [ 19.56622   ],\n",
              "       [ 19.434221  ],\n",
              "       [ 19.816614  ],\n",
              "       [ 20.103207  ],\n",
              "       [ 20.131252  ],\n",
              "       [ 12.636832  ],\n",
              "       [ 14.11509   ],\n",
              "       [ 15.0053835 ],\n",
              "       [ 19.47582   ],\n",
              "       [ 19.607937  ],\n",
              "       [ 20.07389   ],\n",
              "       [ 23.29281   ],\n",
              "       [ 22.93753   ],\n",
              "       [ 21.497654  ],\n",
              "       [ 19.670486  ],\n",
              "       [ 13.89759   ],\n",
              "       [ 13.885154  ],\n",
              "       [ 16.117184  ],\n",
              "       [ 18.346493  ],\n",
              "       [ 19.17769   ],\n",
              "       [ 19.01358   ],\n",
              "       [ 19.194073  ],\n",
              "       [ 18.914787  ],\n",
              "       [ 19.308834  ],\n",
              "       [ 18.686918  ],\n",
              "       [ 17.140675  ],\n",
              "       [ 18.226418  ],\n",
              "       [ 17.518036  ],\n",
              "       [ 18.522408  ],\n",
              "       [ 18.670319  ],\n",
              "       [ 19.03692   ],\n",
              "       [ 18.685965  ],\n",
              "       [ 17.146248  ],\n",
              "       [ 17.87808   ],\n",
              "       [ 17.340504  ],\n",
              "       [ 17.296158  ],\n",
              "       [ 16.731533  ],\n",
              "       [ 16.571785  ],\n",
              "       [ 16.70346   ],\n",
              "       [ 16.602625  ],\n",
              "       [ 15.311063  ],\n",
              "       [ 15.48532   ],\n",
              "       [ 17.337955  ],\n",
              "       [ 16.78215   ],\n",
              "       [ 16.925522  ],\n",
              "       [ 16.853584  ],\n",
              "       [ 16.745375  ],\n",
              "       [ 17.363441  ],\n",
              "       [ 17.518177  ],\n",
              "       [ 17.291552  ],\n",
              "       [ 17.123016  ],\n",
              "       [ 18.895117  ],\n",
              "       [ 19.59476   ],\n",
              "       [ 19.617817  ],\n",
              "       [ 19.32371   ],\n",
              "       [ 15.737905  ],\n",
              "       [ 19.833614  ],\n",
              "       [ 20.654505  ],\n",
              "       [ 20.666603  ],\n",
              "       [ 19.768017  ],\n",
              "       [ 20.051619  ],\n",
              "       [ 19.723238  ],\n",
              "       [ 18.771847  ],\n",
              "       [ 18.475086  ],\n",
              "       [ 18.356777  ],\n",
              "       [ 18.557188  ],\n",
              "       [ 20.176178  ],\n",
              "       [ 19.17928   ],\n",
              "       [ 15.709001  ],\n",
              "       [ 15.238383  ],\n",
              "       [ 15.707671  ],\n",
              "       [ 15.928735  ],\n",
              "       [ 15.28245   ],\n",
              "       [ 15.740556  ],\n",
              "       [ 15.880267  ],\n",
              "       [ 16.079384  ],\n",
              "       [ 15.871417  ],\n",
              "       [ 14.106286  ],\n",
              "       [ 16.095722  ],\n",
              "       [ 14.635734  ],\n",
              "       [ 13.4181185 ],\n",
              "       [ 15.627304  ],\n",
              "       [ 14.626936  ],\n",
              "       [ 14.735538  ],\n",
              "       [ 14.87713   ],\n",
              "       [ 14.671988  ],\n",
              "       [ 14.487165  ],\n",
              "       [ 15.915109  ],\n",
              "       [ 16.99036   ],\n",
              "       [ 14.107782  ],\n",
              "       [ 14.841882  ],\n",
              "       [ 12.66285   ],\n",
              "       [ 12.620022  ],\n",
              "       [ 12.794316  ],\n",
              "       [ 12.220679  ],\n",
              "       [ 13.701011  ],\n",
              "       [ 17.194502  ],\n",
              "       [ 16.93103   ],\n",
              "       [ 17.766233  ],\n",
              "       [ 17.25528   ],\n",
              "       [ 19.220915  ],\n",
              "       [ 17.817776  ],\n",
              "       [ 14.864263  ],\n",
              "       [ 14.901538  ],\n",
              "       [ 14.520577  ],\n",
              "       [ 17.098528  ],\n",
              "       [ 18.931734  ],\n",
              "       [ 18.016968  ],\n",
              "       [ 19.559303  ],\n",
              "       [ 20.306618  ],\n",
              "       [ 20.621603  ],\n",
              "       [ 20.878323  ],\n",
              "       [ 21.033735  ],\n",
              "       [ 20.232307  ],\n",
              "       [ 18.798943  ],\n",
              "       [ 18.275135  ],\n",
              "       [ 13.136308  ],\n",
              "       [ 13.654624  ],\n",
              "       [ 14.082628  ],\n",
              "       [ 14.100865  ],\n",
              "       [ 18.306448  ],\n",
              "       [ 18.643166  ],\n",
              "       [ 17.771362  ],\n",
              "       [ 18.533747  ],\n",
              "       [ 18.493046  ],\n",
              "       [ 18.416132  ],\n",
              "       [ 18.542135  ],\n",
              "       [ 18.93649   ],\n",
              "       [ 19.067875  ],\n",
              "       [ 19.280388  ],\n",
              "       [ 18.847406  ],\n",
              "       [ 19.224918  ],\n",
              "       [ 18.02248   ],\n",
              "       [ 18.11677   ],\n",
              "       [ 17.939404  ],\n",
              "       [ 18.492126  ],\n",
              "       [ 17.158272  ],\n",
              "       [ 15.535195  ],\n",
              "       [ 16.58099   ],\n",
              "       [ 18.22288   ],\n",
              "       [ 18.580227  ],\n",
              "       [ 18.17862   ],\n",
              "       [ 18.239988  ],\n",
              "       [ 18.108826  ],\n",
              "       [ 18.01616   ],\n",
              "       [ 14.51386   ],\n",
              "       [ 14.529257  ],\n",
              "       [ 14.767962  ],\n",
              "       [ 14.182129  ],\n",
              "       [ 14.868746  ],\n",
              "       [ 14.2376    ],\n",
              "       [ 14.044336  ],\n",
              "       [ 14.326677  ],\n",
              "       [ 17.163944  ],\n",
              "       [ 18.559856  ],\n",
              "       [ 20.589947  ],\n",
              "       [ 21.10976   ],\n",
              "       [ 19.414915  ],\n",
              "       [ 18.93996   ],\n",
              "       [ 22.680157  ],\n",
              "       [ 17.983316  ],\n",
              "       [ 20.506937  ],\n",
              "       [ 21.0439    ],\n",
              "       [ 20.88408   ],\n",
              "       [ 22.366074  ],\n",
              "       [ 15.498391  ],\n",
              "       [ 23.256645  ],\n",
              "       [ 23.090197  ],\n",
              "       [ 24.577862  ],\n",
              "       [ 24.73536   ],\n",
              "       [ 23.792545  ],\n",
              "       [ 24.065296  ],\n",
              "       [ 24.686079  ],\n",
              "       [ 26.829231  ],\n",
              "       [ 25.21178   ],\n",
              "       [ 26.613028  ],\n",
              "       [ 25.403788  ],\n",
              "       [ 26.139784  ],\n",
              "       [ 31.356699  ],\n",
              "       [ 34.3411    ],\n",
              "       [ 24.582853  ],\n",
              "       [ 24.1076    ],\n",
              "       [ 22.81176   ],\n",
              "       [ 24.089468  ],\n",
              "       [ 25.106575  ],\n",
              "       [ 24.809193  ],\n",
              "       [ 23.668308  ],\n",
              "       [ 20.133013  ],\n",
              "       [ 23.389164  ],\n",
              "       [ 23.280766  ],\n",
              "       [ 20.510065  ],\n",
              "       [ 21.757263  ],\n",
              "       [  5.235473  ],\n",
              "       [ 22.056734  ],\n",
              "       [ 24.0299    ],\n",
              "       [ 24.38215   ],\n",
              "       [ 31.78275   ],\n",
              "       [ 23.071682  ],\n",
              "       [ 21.333261  ],\n",
              "       [ 21.688639  ],\n",
              "       [ 24.476345  ],\n",
              "       [ 23.992817  ],\n",
              "       [ 24.065342  ],\n",
              "       [ 24.910303  ],\n",
              "       [ 23.782883  ],\n",
              "       [ 22.964952  ],\n",
              "       [ 22.126963  ],\n",
              "       [ 23.562386  ],\n",
              "       [ 24.149323  ],\n",
              "       [ 24.144817  ],\n",
              "       [ 18.401102  ],\n",
              "       [ 28.162518  ],\n",
              "       [ 20.833807  ],\n",
              "       [ 22.417423  ],\n",
              "       [ 24.46954   ],\n",
              "       [ 20.116545  ],\n",
              "       [ 19.637566  ],\n",
              "       [ 11.090453  ],\n",
              "       [ 22.253939  ],\n",
              "       [ 25.957857  ],\n",
              "       [ 31.3179    ],\n",
              "       [ 43.577873  ],\n",
              "       [-37.08182   ],\n",
              "       [  1.0115198 ],\n",
              "       [ -4.1102796 ],\n",
              "       [ 37.955917  ],\n",
              "       [  0.8075022 ],\n",
              "       [ -5.033116  ],\n",
              "       [ -0.8312841 ],\n",
              "       [ 26.364502  ],\n",
              "       [-46.661083  ],\n",
              "       [ 11.68389   ],\n",
              "       [ 28.362597  ],\n",
              "       [ 29.662516  ],\n",
              "       [ 32.0128    ],\n",
              "       [ -4.4347043 ],\n",
              "       [ -2.4741292 ],\n",
              "       [-10.280156  ],\n",
              "       [  5.150024  ],\n",
              "       [-18.847462  ],\n",
              "       [ 33.0124    ],\n",
              "       [ 15.697719  ],\n",
              "       [ 27.284908  ],\n",
              "       [ 23.684868  ],\n",
              "       [ 35.12753   ],\n",
              "       [ 33.00927   ],\n",
              "       [ 26.425209  ],\n",
              "       [ 29.763798  ],\n",
              "       [ -0.9896818 ],\n",
              "       [ -9.91718   ],\n",
              "       [ 17.000584  ],\n",
              "       [ 23.734299  ],\n",
              "       [ 20.836172  ],\n",
              "       [ 23.85905   ],\n",
              "       [ 24.359076  ],\n",
              "       [ 23.76935   ],\n",
              "       [ 39.37888   ],\n",
              "       [  7.6386523 ],\n",
              "       [ 30.374641  ],\n",
              "       [ 23.463255  ],\n",
              "       [ 23.4865    ],\n",
              "       [ 32.021015  ],\n",
              "       [ -6.3832593 ],\n",
              "       [ 26.801098  ],\n",
              "       [ 24.909935  ],\n",
              "       [ 24.618473  ],\n",
              "       [ -6.0500455 ],\n",
              "       [ 16.679165  ],\n",
              "       [  0.39197487],\n",
              "       [ -3.678925  ],\n",
              "       [ 36.55686   ],\n",
              "       [ 23.435135  ],\n",
              "       [ 39.59437   ],\n",
              "       [ 24.647314  ],\n",
              "       [ 23.312983  ],\n",
              "       [ 23.68818   ],\n",
              "       [ 22.322145  ],\n",
              "       [ 30.641687  ],\n",
              "       [  6.3736606 ],\n",
              "       [ 29.817156  ],\n",
              "       [ 22.637384  ],\n",
              "       [ 21.075792  ],\n",
              "       [ 24.369993  ],\n",
              "       [ 24.574894  ],\n",
              "       [ 24.114548  ],\n",
              "       [ 24.32375   ],\n",
              "       [ 26.298811  ],\n",
              "       [ 33.167957  ],\n",
              "       [ 24.539854  ],\n",
              "       [ 25.225601  ],\n",
              "       [ 24.02897   ],\n",
              "       [ 21.814209  ],\n",
              "       [ 22.951876  ],\n",
              "       [ 23.150282  ],\n",
              "       [ 22.979628  ],\n",
              "       [ 24.382751  ],\n",
              "       [ 27.036692  ],\n",
              "       [ 24.093548  ],\n",
              "       [ 24.127745  ],\n",
              "       [ 23.618656  ],\n",
              "       [ 30.460258  ],\n",
              "       [ 36.510082  ],\n",
              "       [ 40.636494  ],\n",
              "       [ 30.75029   ],\n",
              "       [ 30.060522  ],\n",
              "       [ 19.838158  ],\n",
              "       [ 19.980476  ],\n",
              "       [ 20.289854  ],\n",
              "       [ 20.152245  ],\n",
              "       [ 19.826895  ],\n",
              "       [ 19.717495  ],\n",
              "       [ 19.712658  ],\n",
              "       [ 19.616703  ],\n",
              "       [ 19.247822  ],\n",
              "       [ 19.212994  ],\n",
              "       [ 18.77496   ],\n",
              "       [ 18.80803   ],\n",
              "       [ 19.149616  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_i74JEGjjON"
      },
      "source": [
        "- regression도 binary classification 으로 변경 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYArVvkBi5E-",
        "outputId": "d1aa9bb2-c44d-4cb7-afa0-76d1e05373a2"
      },
      "source": [
        "model_boston= tf.keras.models.Sequential([\r\n",
        "                            tf.keras.layers.Dense(16, input_shape=(13,),activation='relu') , #문자열\r\n",
        "                            tf.keras.layers.Dense(16),           #함수\r\n",
        "                            tf.keras.layers.Activation('relu'),  #클래스\r\n",
        "                            tf.keras.layers.Dense(1, activation='sigmoid' ) #binary classification \r\n",
        "\r\n",
        "])\r\n",
        "#sigmoid 함수 적용한 결과\r\n",
        "model_boston(boston.data)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(506, 1), dtype=float32, numpy=\n",
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL_TQGfRj1bh",
        "outputId": "3512a1ff-00e0-4714-871c-7e43ef625722"
      },
      "source": [
        "model_boston= tf.keras.models.Sequential([\r\n",
        "                            tf.keras.layers.Dense(16, input_shape=(13,),activation='relu') , #문자열\r\n",
        "                            tf.keras.layers.Dense(16),           #함수\r\n",
        "                            tf.keras.layers.Activation('relu'),  #클래스\r\n",
        "                            tf.keras.layers.Dense(2, activation='softmax' ) #binary classification \r\n",
        "\r\n",
        "])\r\n",
        "#softmax 함수 적용한 결과\r\n",
        "model_boston(boston.data)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(506, 2), dtype=float32, numpy=\n",
              "array([[1.0255241e-15, 1.0000000e+00],\n",
              "       [8.6293221e-09, 1.0000000e+00],\n",
              "       [9.2071950e-09, 1.0000000e+00],\n",
              "       ...,\n",
              "       [2.1974339e-12, 1.0000000e+00],\n",
              "       [1.2615431e-12, 1.0000000e+00],\n",
              "       [2.3876313e-12, 1.0000000e+00]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbumNHZEkScR"
      },
      "source": [
        "- convolution 2d\r\n",
        "  - 나중에 자세히 다룰 예정\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnkXuTycjLKT"
      },
      "source": [
        "tf.keras.layers.Conv2D ( )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLavNco55x_m"
      },
      "source": [
        "## 1단계\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAQlT-hprAMq"
      },
      "source": [
        "model_boston= tf.keras.models.Sequential([\r\n",
        "                            tf.keras.layers.Dense(16, input_shape=(13,),activation='relu') , #문자열\r\n",
        "                            tf.keras.layers.Dense(16),           #함수\r\n",
        "                            tf.keras.layers.Activation('relu'),  #클래스\r\n",
        "                            tf.keras.layers.Dense(1 )            #regression-> output 1개 (변형x)\r\n",
        "\r\n",
        "])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O1ufcSRrNGh",
        "outputId": "bc085579-b17b-4d6a-c985-a53ef096ba1a"
      },
      "source": [
        "model_boston(data.data).numpy() -data.target"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-167.49227905, -165.09227905, -178.19227905, ..., -167.39227905,\n",
              "        -165.49227905, -155.39227905],\n",
              "       [-148.29197693, -145.89197693, -158.99197693, ..., -148.19197693,\n",
              "        -146.29197693, -136.19197693],\n",
              "       [-146.25218201, -143.85218201, -156.95218201, ..., -146.15218201,\n",
              "        -144.25218201, -134.15218201],\n",
              "       ...,\n",
              "       [-158.60009766, -156.20009766, -169.30009766, ..., -158.50009766,\n",
              "        -156.60009766, -146.50009766],\n",
              "       [-158.05776978, -155.65776978, -168.75776978, ..., -157.95776978,\n",
              "        -156.05776978, -145.95776978],\n",
              "       [-158.00535583, -155.60535583, -168.70535583, ..., -157.90535583,\n",
              "        -156.00535583, -145.90535583]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfBycCz9snYz"
      },
      "source": [
        "- 장점: 빠른 예측\r\n",
        "  - predict 는 데이터 단순하게 모델에 입력\r\n",
        "실시간 시스템에도 사용 가능\r\n",
        "  - vectorization , GPU로 더 빠름\r\n",
        "- 단점: 학습이 잘 안되고 느림\r\n",
        "  - 리소스 필요\r\n",
        "  - 데이터 양 , 컴퓨팅 파워(느린 학습 속도), 새로운 알고리즘\r\n",
        "> KNN : case by learning :학습은 빠르나 예측 느림"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf8264XvrO-Z",
        "outputId": "7dd74b4e-1e4d-4006-c499-0401355fbd0e"
      },
      "source": [
        "model_boston.predict(data.data) == model_boston(data.data).numpy()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJn1BKQgupqY"
      },
      "source": [
        "### back propagation\r\n",
        "- 각 레이어의  kernel , bias 값 업데이트** 해서 최소화\r\n",
        " - 미분 chain rule\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBiUaIHmsk7a",
        "outputId": "29cb2b58-3c4e-4f07-f38e-ed85b629dbaf"
      },
      "source": [
        "model_boston.layers[0].kernel, model_boston.layers[0].bias"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'dense_31/kernel:0' shape=(13, 16) dtype=float32, numpy=\n",
              " array([[ 0.03287032, -0.29305512, -0.35196158, -0.2432018 ,  0.1313588 ,\n",
              "          0.38183022,  0.28721255,  0.35686076,  0.42332512,  0.31442666,\n",
              "         -0.00515458, -0.2833883 , -0.14665845,  0.4255073 ,  0.43596935,\n",
              "         -0.08507076],\n",
              "        [-0.03233784,  0.2056086 , -0.12149501,  0.1427967 ,  0.36204857,\n",
              "         -0.20503527, -0.35942653,  0.07042611, -0.07687315,  0.18337834,\n",
              "         -0.0752303 ,  0.27389085,  0.3464499 , -0.40106565, -0.407713  ,\n",
              "          0.18413204],\n",
              "        [-0.24279861, -0.3812301 , -0.15177357,  0.22928774, -0.08626586,\n",
              "         -0.1819618 ,  0.01652837, -0.22614671, -0.40516862,  0.16503453,\n",
              "         -0.38903815, -0.10548761,  0.20473075,  0.27988625, -0.4494967 ,\n",
              "         -0.36311945],\n",
              "        [-0.15030488,  0.17578161,  0.02602366, -0.01945242,  0.05836803,\n",
              "         -0.23231885, -0.3399164 , -0.30073553,  0.11305231,  0.01645377,\n",
              "          0.39699042, -0.32896066,  0.45101768, -0.3808735 , -0.10000974,\n",
              "          0.3378467 ],\n",
              "        [ 0.30109984, -0.08602965,  0.39613867, -0.05608305,  0.26769745,\n",
              "         -0.1260297 , -0.30352253,  0.2727682 , -0.10199705, -0.06378037,\n",
              "         -0.01818305,  0.28908294, -0.20399061,  0.08890134, -0.30954134,\n",
              "         -0.03173155],\n",
              "        [ 0.22187835, -0.30838746,  0.10246921,  0.42539483,  0.09005499,\n",
              "          0.13142776,  0.09139431, -0.43326795,  0.4419812 , -0.28782672,\n",
              "         -0.40448356,  0.12084305, -0.08386895,  0.43794787,  0.15520102,\n",
              "         -0.4439363 ],\n",
              "        [ 0.00276181, -0.3808326 ,  0.11901116, -0.42553732,  0.34229517,\n",
              "          0.16759151,  0.18700695, -0.3973969 , -0.02341801,  0.26612043,\n",
              "          0.13824731,  0.30928618,  0.07776016,  0.01146793,  0.01075488,\n",
              "          0.18341434],\n",
              "        [-0.03968957, -0.25431836, -0.2831356 , -0.2573526 ,  0.11196923,\n",
              "          0.2881747 , -0.11326563,  0.20895094,  0.26509005, -0.23119003,\n",
              "         -0.26000726, -0.2868175 ,  0.03292444,  0.11131817, -0.03040403,\n",
              "          0.19669265],\n",
              "        [-0.06398687,  0.18577313,  0.24842852,  0.34826583, -0.4363151 ,\n",
              "          0.16477299,  0.11999714, -0.3254945 , -0.31388006, -0.18447268,\n",
              "         -0.385683  ,  0.01109681,  0.21355635,  0.03401706, -0.06255817,\n",
              "         -0.07050896],\n",
              "        [ 0.311175  , -0.15026951, -0.04834786,  0.01541018, -0.44966954,\n",
              "          0.22871429, -0.02002048, -0.18658444, -0.38117695, -0.19491565,\n",
              "          0.33447117,  0.06677198,  0.05224395, -0.05394524, -0.29684132,\n",
              "         -0.35785773],\n",
              "        [ 0.11750364, -0.16813028, -0.16001293,  0.07838023, -0.26917103,\n",
              "          0.41246784, -0.09408313, -0.2703004 , -0.4444464 , -0.15631998,\n",
              "         -0.3723536 ,  0.4035676 ,  0.14567864,  0.29204345, -0.38429618,\n",
              "         -0.23064043],\n",
              "        [-0.14603934, -0.33745694,  0.2626717 ,  0.01808622,  0.40238696,\n",
              "         -0.27319634, -0.23297268, -0.24144432,  0.10812461,  0.128456  ,\n",
              "          0.16296995,  0.4099869 , -0.22503209,  0.4318418 , -0.3549055 ,\n",
              "          0.03113812],\n",
              "        [ 0.15474695,  0.37606692, -0.28849885, -0.4249928 ,  0.41564643,\n",
              "         -0.3404569 ,  0.10504127,  0.27337974,  0.05144119, -0.10623741,\n",
              "          0.18492872,  0.01139894,  0.19239396,  0.06614298,  0.32652992,\n",
              "          0.16346318]], dtype=float32)>,\n",
              " <tf.Variable 'dense_31/bias:0' shape=(16,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_F6Fq_Xu6-F"
      },
      "source": [
        "## 2단계\r\n",
        "### compile\r\n",
        "- 학습 전략 \r\n",
        "- 신경망 구성, 실제값 사용하도록 내부값 변화시킴\r\n",
        "- 실제 사용하기 위해 변환 과정 필요했었으나 과정없이 연산했었음\r\n",
        "\r\n",
        "- tf1: 컴파일 (빠름)\r\n",
        "- pytorch, tf2  : 즉기 결과값 얻기 때문에 느림\r\n",
        "    - JIT(Just In Time) 으로 최적화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU5bhttDrD2I"
      },
      "source": [
        "#### loss\r\n",
        "- feed forward 하여 최종 아웃풋인 예측값 y hat과 실제값 y 의 **차이를 최소화**\r\n",
        "  - regression\r\n",
        "    - MSE(Mean Squared Error)=  실제값 -예측값\r\n",
        "- gradient descent 방식으로 최소점 찾음\r\n",
        "  - 미분 가능한 함수\r\n",
        "  > NFL 데이터에 따라 상황 상이하기 때문에 평가 통해 찾음\r\n",
        "\r\n",
        "#### optimizer\r\n",
        "  - optimizer 알고리즘 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwq5RXrgus9U"
      },
      "source": [
        "model_boston.compile (loss= tf.keras.losses.mean_squared_error)\r\n",
        "model_boston.compile (loss='mse')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnU4m40IsCoF"
      },
      "source": [
        "model_boston.compile (optimizer='adam')\r\n",
        "model_boston.compile (optimizer=tf.keras.optimizers.Adam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpkqyN5nvAdC"
      },
      "source": [
        "tf.keras.optimizers.Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8qYI1_3y_Y2"
      },
      "source": [
        "#### metrics\r\n",
        " - 성능 평가 척도\r\n",
        " 예. 이상탐지인 경우 정확도는 동일하므로 정확도는 의미가 없으며 recall 이 더 유의미\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFBRB9Q-ytpu"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix # 상황에 맞는 성능 평가  ( accuracy, recall ,f1 score, roc curve)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCiusCLcza1H"
      },
      "source": [
        "# loss, optimizer, metrics 지정\r\n",
        "model_boston.compile (loss='mse',optimizer='adam', metrics=['mse','mae'])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfAdXflNzqdl"
      },
      "source": [
        "## 3단계\r\n",
        "### fit\r\n",
        "- 모델 학습\r\n",
        "찾아야하는 weight,bias 많음\r\n",
        "#### epoch \r\n",
        "- 전체 데이터를 여러번 학습 시키는 횟수\r\n",
        "- 너무 많이하면 overfitting 되기 때문에 유의\r\n",
        "  - early stopping\r\n",
        "\r\n",
        "#### mini batch\r\n",
        "- batch size 만큼 학습 후 웨이트 업데이트\r\n",
        "  - batch size 가 작을수록 학습 속도는 느리나 정확도는 비교적 높음(적은 메모리)\r\n",
        "  - batch size 가 클수록 학습 속도는 빠르나 정확도는 비교적 낮음 \r\n",
        "  - 예. 1문제씩 보고 답보기 vs 30문제 보고 답보기\r\n",
        "  - 1 문제씩 보고 답 풀면 틀린 부분은 덜 틀리게 되지만 속도가 느려짐\r\n",
        "  - \r\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpOdCcDiznjO"
      },
      "source": [
        "model.fit\r\n",
        "model.fit_generator  #Image에서 중요함\r\n",
        "model.train_on_batch\r\n",
        "model.train_step\r\n",
        "model.train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C5-mt4Y5pXQ",
        "outputId": "7dc73039-ea84-4d2a-da8a-b2070a0f47a9"
      },
      "source": [
        "model_boston.fit( boston.data, boston.target ) #X,y 필수"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 1ms/step - loss: 95.4573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fc1f74a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzhGetgT9JXz",
        "outputId": "4d577446-54b3-4750-bff4-38195465be2e"
      },
      "source": [
        "model_boston.fit( boston.data, boston.target ,epochs=5) #loss 가 줄어들고 있음"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 176.8190 - mse: 176.8190 - mae: 10.4720\n",
            "Epoch 2/5\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 127.1570 - mse: 127.1570 - mae: 8.5635\n",
            "Epoch 3/5\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 104.2285 - mse: 104.2285 - mae: 7.6693\n",
            "Epoch 4/5\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 92.1737 - mse: 92.1737 - mae: 7.1260\n",
            "Epoch 5/5\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 86.6212 - mse: 86.6212 - mae: 6.8111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fc1e42128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fusQ-ZXW9T0B"
      },
      "source": [
        "모델을 잘 못 만드는 경우 loss가 줄어들지 않음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJZiOs0n94hQ"
      },
      "source": [
        "### 이미지 데이터 이용한 신경망\r\n",
        "[텐서플로 2.0 시작하기: 초보자용\r\n",
        "](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ko)\r\n",
        "- 0~9 숫자 이미지 데이터 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVjEcj7h9LmC",
        "outputId": "d2fc788b-0753-45a0-fc13-e406c2a53b59"
      },
      "source": [
        "#holdout\r\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "NtshJVOz-PVO",
        "outputId": "1f014a79-6be4-4b74-9da0-6a7cc75b43e6"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.imshow(X_train[0],cmap='gray') #2차원 흑백데이터 (간단)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6fc0c60978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN9klEQVR4nO3df4xV9ZnH8c+zWP6QojBrOhKKSyEGg8ZON4gbl6w1hvojGhw1TSexoZE4/YNJaLIhNewf1WwwZBU2SzTNTKMWNl1qEzUgaQouoOzGhDgiKo5LdQ2mTEaowZEf/mCHefaPezBTnfu9w7nn3nOZ5/1Kbu6957nnnicnfDi/7pmvubsATH5/VXYDAJqDsANBEHYgCMIOBEHYgSAuaubCzIxT/0CDubuNN72uLbuZ3Wpmh8zsPTN7sJ7vAtBYlvc6u5lNkfRHSUslHZH0qqQudx9IzMOWHWiwRmzZF0t6z93fd/czkn4raVkd3weggeoJ+2xJfxrz/kg27S+YWbeZ9ZtZfx3LAlCnhp+gc/c+SX0Su/FAmerZsg9KmjPm/bezaQBaUD1hf1XSlWb2HTObKulHkrYV0xaAouXejXf3ETPrkbRD0hRJT7n724V1BqBQuS+95VoYx+xAwzXkRzUALhyEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBJF7yGZcGKZMmZKsX3rppQ1dfk9PT9XaxRdfnJx3wYIFyfrKlSuT9ccee6xqraurKznv559/nqyvW7cuWX/44YeT9TLUFXYzOyzppKSzkkbcfVERTQEoXhFb9pvc/aMCvgdAA3HMDgRRb9hd0k4ze83Musf7gJl1m1m/mfXXuSwAdah3N36Juw+a2bckvWhm/+Pue8d+wN37JPVJkpl5ncsDkFNdW3Z3H8yej0l6XtLiIpoCULzcYTezaWY2/dxrST+QdLCoxgAUq57d+HZJz5vZue/5D3f/QyFdTTJXXHFFsj516tRk/YYbbkjWlyxZUrU2Y8aM5Lz33HNPsl6mI0eOJOsbN25M1js7O6vWTp48mZz3jTfeSNZffvnlZL0V5Q67u78v6bsF9gKggbj0BgRB2IEgCDsQBGEHgiDsQBDm3rwftU3WX9B1dHQk67t3707WG32baasaHR1N1u+///5k/dSpU7mXPTQ0lKx//PHHyfqhQ4dyL7vR3N3Gm86WHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeC4Dp7Adra2pL1ffv2Jevz5s0rsp1C1ep9eHg4Wb/pppuq1s6cOZOcN+rvD+rFdXYgOMIOBEHYgSAIOxAEYQeCIOxAEIQdCIIhmwtw/PjxZH316tXJ+h133JGsv/7668l6rT+pnHLgwIFkfenSpcn66dOnk/Wrr766am3VqlXJeVEstuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EAT3s7eASy65JFmvNbxwb29v1dqKFSuS8953333J+pYtW5J1tJ7c97Ob2VNmdszMDo6Z1mZmL5rZu9nzzCKbBVC8iezG/1rSrV+Z9qCkXe5+paRd2XsALaxm2N19r6Sv/h50maRN2etNku4quC8ABcv72/h2dz83WNaHktqrfdDMuiV151wOgILUfSOMu3vqxJu790nqkzhBB5Qp76W3o2Y2S5Ky52PFtQSgEfKGfZuk5dnr5ZK2FtMOgEapuRtvZlskfV/SZWZ2RNIvJK2T9DszWyHpA0k/bGSTk92JEyfqmv+TTz7JPe8DDzyQrD/zzDPJeq0x1tE6aobd3buqlG4uuBcADcTPZYEgCDsQBGEHgiDsQBCEHQiCW1wngWnTplWtvfDCC8l5b7zxxmT9tttuS9Z37tyZrKP5GLIZCI6wA0EQdiAIwg4EQdiBIAg7EARhB4LgOvskN3/+/GR9//79yfrw8HCyvmfPnmS9v7+/au2JJ55IztvMf5uTCdfZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIrrMH19nZmaw//fTTyfr06dNzL3vNmjXJ+ubNm5P1oaGhZD0qrrMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBBcZ0fSNddck6xv2LAhWb/55vyD/fb29ibra9euTdYHBwdzL/tClvs6u5k9ZWbHzOzgmGkPmdmgmR3IHrcX2SyA4k1kN/7Xkm4dZ/q/untH9vh9sW0BKFrNsLv7XknHm9ALgAaq5wRdj5m9me3mz6z2ITPrNrN+M6v+x8gANFzesP9S0nxJHZKGJK2v9kF373P3Re6+KOeyABQgV9jd/ai7n3X3UUm/krS42LYAFC1X2M1s1pi3nZIOVvssgNZQ8zq7mW2R9H1Jl0k6KukX2fsOSS7psKSfunvNm4u5zj75zJgxI1m/8847q9Zq3StvNu7l4i/t3r07WV+6dGmyPllVu85+0QRm7Bpn8pN1dwSgqfi5LBAEYQeCIOxAEIQdCIKwA0FwiytK88UXXyTrF12Uvlg0MjKSrN9yyy1Vay+99FJy3gsZf0oaCI6wA0EQdiAIwg4EQdiBIAg7EARhB4KoedcbYrv22muT9XvvvTdZv+6666rWal1Hr2VgYCBZ37t3b13fP9mwZQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBILjOPsktWLAgWe/p6UnW77777mT98ssvP++eJurs2bPJ+tBQ+q+Xj46OFtnOBY8tOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwXX2C0Cta9ldXeMNtFtR6zr63Llz87RUiP7+/mR97dq1yfq2bduKbGfSq7llN7M5ZrbHzAbM7G0zW5VNbzOzF83s3ex5ZuPbBZDXRHbjRyT9o7svlPR3klaa2UJJD0ra5e5XStqVvQfQomqG3d2H3H1/9vqkpHckzZa0TNKm7GObJN3VqCYB1O+8jtnNbK6k70naJ6nd3c/9OPlDSe1V5umW1J2/RQBFmPDZeDP7pqRnJf3M3U+MrXlldMhxB2109z53X+Tui+rqFEBdJhR2M/uGKkH/jbs/l00+amazsvosScca0yKAItTcjTczk/SkpHfcfcOY0jZJyyWty563NqTDSaC9fdwjnC8tXLgwWX/88ceT9auuuuq8eyrKvn37kvVHH320am3r1vQ/GW5RLdZEjtn/XtKPJb1lZgeyaWtUCfnvzGyFpA8k/bAxLQIoQs2wu/t/Sxp3cHdJNxfbDoBG4eeyQBCEHQiCsANBEHYgCMIOBMEtrhPU1tZWtdbb25uct6OjI1mfN29erp6K8MorryTr69evT9Z37NiRrH/22Wfn3RMagy07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQR5jr79ddfn6yvXr06WV+8eHHV2uzZs3P1VJRPP/20am3jxo3JeR955JFk/fTp07l6Quthyw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQYS5zt7Z2VlXvR4DAwPJ+vbt25P1kZGRZD11z/nw8HByXsTBlh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3T3/AbI6kzZLaJbmkPnf/NzN7SNIDkv6cfXSNu/++xnelFwagbu4+7qjLEwn7LEmz3H2/mU2X9Jqku1QZj/2Uuz820SYIO9B41cI+kfHZhyQNZa9Pmtk7ksr90ywAztt5HbOb2VxJ35O0L5vUY2ZvmtlTZjazyjzdZtZvZv11dQqgLjV347/8oNk3Jb0saa27P2dm7ZI+UuU4/p9V2dW/v8Z3sBsPNFjuY3ZJMrNvSNouaYe7bxinPlfSdne/psb3EHagwaqFveZuvJmZpCclvTM26NmJu3M6JR2st0kAjTORs/FLJP2XpLckjWaT10jqktShym78YUk/zU7mpb6LLTvQYHXtxheFsAONl3s3HsDkQNiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQii2UM2fyTpgzHvL8umtaJW7a1V+5LoLa8ie/ubaoWm3s/+tYWb9bv7otIaSGjV3lq1L4ne8mpWb+zGA0EQdiCIssPeV/LyU1q1t1btS6K3vJrSW6nH7ACap+wtO4AmIexAEKWE3cxuNbNDZvaemT1YRg/VmNlhM3vLzA6UPT5dNobeMTM7OGZam5m9aGbvZs/jjrFXUm8Pmdlgtu4OmNntJfU2x8z2mNmAmb1tZquy6aWuu0RfTVlvTT9mN7Mpkv4oaamkI5JeldTl7gNNbaQKMzssaZG7l/4DDDP7B0mnJG0+N7SWmf2LpOPuvi77j3Kmu/+8RXp7SOc5jHeDeqs2zPhPVOK6K3L48zzK2LIvlvSeu7/v7mck/VbSshL6aHnuvlfS8a9MXiZpU/Z6kyr/WJquSm8twd2H3H1/9vqkpHPDjJe67hJ9NUUZYZ8t6U9j3h9Ra4337pJ2mtlrZtZddjPjaB8zzNaHktrLbGYcNYfxbqavDDPeMusuz/Dn9eIE3dctcfe/lXSbpJXZ7mpL8soxWCtdO/2lpPmqjAE4JGl9mc1kw4w/K+ln7n5ibK3MdTdOX01Zb2WEfVDSnDHvv51NawnuPpg9H5P0vCqHHa3k6LkRdLPnYyX38yV3P+ruZ919VNKvVOK6y4YZf1bSb9z9uWxy6etuvL6atd7KCPurkq40s++Y2VRJP5K0rYQ+vsbMpmUnTmRm0yT9QK03FPU2Scuz18slbS2xl7/QKsN4VxtmXCWvu9KHP3f3pj8k3a7KGfn/lfRPZfRQpa95kt7IHm+X3ZukLars1v2fKuc2Vkj6a0m7JL0r6T8ltbVQb/+uytDeb6oSrFkl9bZElV30NyUdyB63l73uEn01Zb3xc1kgCE7QAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3fKwgWY-VqE",
        "outputId": "e0cf7fc4-f187-4654-a69c-550c686fecde"
      },
      "source": [
        "X_train.shape #Numpy 포맷 -> Tensorflow에 넣으면 Tensor로 호환됨(리소스)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqgp9I4g-qco"
      },
      "source": [
        "차원 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVnCBEjN_C6Z"
      },
      "source": [
        "X_train_re =X_train.reshape(60000,-1) #2차원화 (6만, 784)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOg9oeZYE7dd"
      },
      "source": [
        "tf.keras.Sequential 은 aliasing\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFFb5Erw-fi9"
      },
      "source": [
        "#3번째 유형 Sequential\r\n",
        "\r\n",
        "model=tf.keras.models.Sequential([ \r\n",
        "                                  #이미지 데이터를 1차원\r\n",
        "                                  tf.keras.layers.Dense( 128, input_shape=(28*28,), activation='relu'),\r\n",
        "                                   tf.keras.layers.Dense( 64, activation='relu'),\r\n",
        "                                   tf.keras.layers.Dense( 10) #10 클래스 분류\r\n",
        "])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxI-nDEYCqk0"
      },
      "source": [
        "#### one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjqVKfzq_EYI",
        "outputId": "2ca9720c-f252-4790-a752-137fbf34ec0f"
      },
      "source": [
        "tf.keras.utils.to_categorical(y_train) #one-hot encoding"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVUfUsan_j1G"
      },
      "source": [
        "y_train_ohe= tf.keras.utils.to_categorical(y_train)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT1kTJ5LBl7z"
      },
      "source": [
        "#### categorical_crossentropy\r\n",
        "- one-hot encoding 된 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATkzI6__vdA"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgXqyOIpACGw",
        "outputId": "9b95fce9-a921-4ecf-f063-0f6a9e934377"
      },
      "source": [
        "model.fit(X_train_re , y_train_ohe, epochs=2)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 9.9306 - acc: 0.2089\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.7918 - acc: 0.2025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fc3fa0668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scx7LiSqARAA",
        "outputId": "a7c60544-4812-48e6-ee77-357386e297e4"
      },
      "source": [
        "y_train_ohe.shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3VAsx4gBRYF"
      },
      "source": [
        "#### sparse_categorical_crossentropy\r\n",
        "- label encoding인 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMTpB988Awwn"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNzvH30vBNO-",
        "outputId": "5636574d-afcc-4c00-99aa-9742431592ea"
      },
      "source": [
        "model.fit(X_train_re , y_train, epochs=2) "
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 8.6078 - acc: 0.1459\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 10.4005 - acc: 0.1262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fc2c80710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lMnZLe6B2hr"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M12hS1gRBOek",
        "outputId": "0dc732fc-b811-49c5-8840-ea1b47bc02cc"
      },
      "source": [
        "model.predict(X_test.reshape(10000,-1) )"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1422.5687, -2622.484 , -1084.2218, ...,  1213.7386,  -786.6462,\n",
              "        -2283.829 ],\n",
              "       [ 1794.9056, -3114.4846, -1418.9469, ...,  1430.1992, -1169.6106,\n",
              "        -2652.1821],\n",
              "       [ 1033.1715, -1396.0286, -1042.8071, ...,   810.2873,  -712.9575,\n",
              "        -1455.4816],\n",
              "       ...,\n",
              "       [ 2266.9006, -4006.7124, -1673.5641, ...,  1817.6796, -1124.0057,\n",
              "        -3546.2922],\n",
              "       [ 1985.3179, -3200.0625, -1599.8854, ...,  1496.7762, -1268.4961,\n",
              "        -2903.704 ],\n",
              "       [ 2749.1091, -5804.501 , -1612.6287, ...,  2345.4148, -1773.743 ,\n",
              "        -4854.3477]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ckBRNXfB685",
        "outputId": "f1f042c3-f498-4b8a-d8a3-231dd0f064ff"
      },
      "source": [
        "model(X_test.reshape(10000,-1))\r\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10000, 10), dtype=float32, numpy=\n",
              "array([[ 1422.5687, -2622.484 , -1084.2218, ...,  1213.7386,  -786.6462,\n",
              "        -2283.829 ],\n",
              "       [ 1794.9056, -3114.4846, -1418.9469, ...,  1430.1992, -1169.6106,\n",
              "        -2652.1821],\n",
              "       [ 1033.1715, -1396.0286, -1042.8071, ...,   810.2873,  -712.9575,\n",
              "        -1455.4816],\n",
              "       ...,\n",
              "       [ 2266.9006, -4006.7124, -1673.5641, ...,  1817.6796, -1124.0057,\n",
              "        -3546.2922],\n",
              "       [ 1985.3179, -3200.0625, -1599.8854, ...,  1496.7762, -1268.4961,\n",
              "        -2903.704 ],\n",
              "       [ 2749.1091, -5804.501 , -1612.6287, ...,  2345.4148, -1773.743 ,\n",
              "        -4854.3477]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYp08ppBCEIV",
        "outputId": "96988373-8b07-4bf7-9672-a148e4aa5602"
      },
      "source": [
        "model.predict(X_test.reshape(10000,-1) )[0]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1422.5687, -2622.484 , -1084.2218, -1060.1813, -2510.3374,\n",
              "        1096.0192, -1776.5771,  1213.7386,  -786.6462, -2283.829 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5IMoeQB6mz"
      },
      "source": [
        "#### softmax\r\n",
        "- output layer의 결과값을 확률처럼 보여줌 (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj3KeCfxCLLz",
        "outputId": "74fcde54-ba13-4b59-90e9-14171eea75ec"
      },
      "source": [
        "model=tf.keras.models.Sequential([ \r\n",
        "                                  #이미지 데이터를 1차원\r\n",
        "                                  tf.keras.layers.Dense( 128, input_shape=(28*28,), activation='relu'),\r\n",
        "                                   tf.keras.layers.Dense( 64, activation='relu'),\r\n",
        "                                   tf.keras.layers.Dense( 10, activation='softmax') #10 클래스 분류\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n",
        "              optimizer='adam', metrics=['acc'])\r\n",
        "\r\n",
        "model.fit(X_train_re , y_train_ohe, epochs=2) "
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 5.6376 - acc: 0.7866\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3193 - acc: 0.9193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fbcff6550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyJmM_sPCQ2W",
        "outputId": "98c687a1-71ae-443e-b3fb-faf66c04fbbc"
      },
      "source": [
        "model.predict(X_test.reshape(10000,-1))[0] #해석이 쉬움"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.2635799e-10, 4.3180200e-05, 9.5204712e-07, 1.7464263e-06,\n",
              "       7.4331770e-11, 5.0226449e-06, 1.3756730e-12, 9.9994886e-01,\n",
              "       2.7057888e-07, 1.4547307e-08], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7_oaXnJDJ-X",
        "outputId": "d4f7cf93-d9c1-4c99-f519-a54f9e87315b"
      },
      "source": [
        "np.argmax(model.predict(X_test.reshape(10000,-1))[0]) #7번째로 예측"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0gs2O8KDgXT"
      },
      "source": [
        "### flatten\r\n",
        "- 모델 자체에서 1차원화 \r\n",
        "- 기존 데이터셋 변경 없이 바로 모델에 넣을 수 있어 편리함\r\n",
        "- (6만, 28,28) -> (6만, 784)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2wMF7X-D4Fh"
      },
      "source": [
        "model=tf.keras.models.Sequential([ \r\n",
        "                                  tf.keras.layers.Flatten(input_shape=(28,28) )\r\n",
        "])"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAv4d_jVEGgp",
        "outputId": "de6317ec-57b6-4967-eb21-fa626dd8d9b1"
      },
      "source": [
        "np.array_equal(model(X_train).numpy(),X_train_re ) #1차원한것과 동일함"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtvl0DI1DWae",
        "outputId": "6b6e9c8c-ee70-41da-c264-9e485b725617"
      },
      "source": [
        "#1단계\r\n",
        "model=tf.keras.models.Sequential([ \r\n",
        "                                  tf.keras.layers.Flatten(input_shape=(28,28) ), #1차원화 \r\n",
        "                                  tf.keras.layers.Dense( 128,  activation='relu'),\r\n",
        "                                   tf.keras.layers.Dense( 64, activation='relu'),\r\n",
        "                                   tf.keras.layers.Dense( 10, activation='softmax') #10 클래스 분류\r\n",
        "])\r\n",
        "#2단계\r\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n",
        "              optimizer='adam', metrics=['acc'])\r\n",
        "#3단계 \r\n",
        "model.fit(X_train , y_train_ohe, epochs=2)  "
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 4.9663 - acc: 0.7903\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3363 - acc: 0.9156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6fba360630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQqvT8ZRF2bd"
      },
      "source": [
        "- 상황마다 필요한 데이터 형태가 상이함\r\n",
        "- end-to-end 모델 내에서 convolution연산 결과를 넘겨서 classifier에 붙임"
      ]
    }
  ]
}