{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210225_7기_고급시각저녁",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbtDRiitiRyd"
      },
      "source": [
        "# [ICTCOG AI Academy] 7기 고급시각저녁반\r\n",
        "# 다양한 CNN 모델 (2)\r\n",
        "\r\n",
        "- 레리어 깊어지면서 다양한 특징들을 detection 가능\r\n",
        "  - 계산 복잡도 증가\r\n",
        "  - FCNN 은 간단\r\n",
        "\r\n",
        "### Convolution 특징\r\n",
        "- invariant\r\n",
        "- 특징과 유사한 경우 값이 커짐\r\n",
        "  - 컨볼루션 단점 : 위치와 상관 없이 특직 여부만 확인\r\n",
        "  - Capsule Network \r\n",
        "- 추상화\r\n",
        "- Convolution된 결과를 1차원화해서 classifier 에 입력되야함\r\n",
        "- 변환된 \r\n",
        "\r\n",
        "### Global Average Poling\r\n",
        "- Flatten 하여 FCNN 입력하는 대신에 특징들 각각을 하나의 값으로 바꿈\r\n",
        "- regularizer 역할\r\n",
        "- 과적합 방지\r\n",
        "- 데이터가 부족한 경우의 성능 문제점\r\n",
        "- 예시: https://www.tensorflow.org/tutorials/keras/text_classification?hl=ko\r\n",
        "### LeNet5 구현\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC5522hfiRCg"
      },
      "source": [
        "# Global average pooling 사용한 예시\r\n",
        "vocab_size = 10000\r\n",
        "\r\n",
        "model = keras.Sequential()\r\n",
        "model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,)))\r\n",
        "model.add(keras.layers.GlobalAveragePooling1D())          #GAP\r\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\r\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za_e-E5KrwEA"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgca96a7rzHb"
      },
      "source": [
        "(X_train, y_train),(X_test,y_test)=tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIqVTXrxtAYs"
      },
      "source": [
        "- 당시 GPU 없었음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqRoeHAAr6PK"
      },
      "source": [
        "inputs= tf.keras.Input(shape=(32,32,1))\r\n",
        "x=tf.keras.layers.Conv2D(6,5, padding='valid')(inputs)\r\n",
        "x=tf.keras.layers.Activation('tanh')(x)\r\n",
        "x=tf.keras.layers.MaxPool2D((2,2),(2,2))(x)\r\n",
        "x=tf.keras.layers.Conv2D(16,5, padding='valid')(x)\r\n",
        "x=tf.keras.layers.Activation('tanh')(x)\r\n",
        "x=tf.keras.layers.MaxPool2D((2,2),(2,2))(x)\r\n",
        "x=tf.keras.layers.Flatten()(x)\r\n",
        "x=tf.keras.layers.Dense(120)(x)\r\n",
        "x=tf.keras.layers.Activation('tanh')(x)\r\n",
        "x=tf.keras.layers.Dense(84)(x)\r\n",
        "x=tf.keras.layers.Activation('tanh')(x)\r\n",
        "x=tf.keras.layers.Dense(10)(x)\r\n",
        "x=tf.keras.layers.Activation('tanh')(x)\r\n",
        "outputs = tf.keras.layers.Dense(10)(x)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek4fD5R6sZ70"
      },
      "source": [
        "model=tf.keras.models.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMdeVfRVse3Y",
        "outputId": "0b18ecf7-98db-4f00-ecac-981e6b4acfbc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "=================================================================\n",
            "Total params: 2,572\n",
            "Trainable params: 2,572\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4-wb63Nwh-u"
      },
      "source": [
        "### Imagenet\r\n",
        "- 1000개의 이미지를 분류하는 대회\r\n",
        "- CNN 모델 하나인 AlexNet 이후 급격히 성능 향상되면서 인기를 얻음\r\n",
        "#### ImageNet Classification with deep convolution al neural networks\r\n",
        "#### AlexNet\r\n",
        "- 2012년 Imagenet에서 1등\r\n",
        "- 목적: 1000가지 이미지 분류\r\n",
        "- 60 milion parameters\r\n",
        "- 여러개 GPU 사용\r\n",
        "- ReLU activation function 사용\r\n",
        "  - 항상 좋지는 않음\r\n",
        "- LRN Local Response Normalization\r\n",
        "  - LCN 대신 LRN\r\n",
        "  - 요즘 사용하지 않음\r\n",
        "- overlapping pooling\r\n",
        "  - 특징 파악에는 좋음\r\n",
        "  - 연산 복잡도 상승\r\n",
        "- 그룹 컨볼루션\r\n",
        "  - 하나의 레이어를 분리 시켜서 연산 할 수 있음\r\n",
        "  - 그룹간의 연산이 단순해지는 장점\r\n",
        "\r\n",
        "- 11x11 kernel\r\n",
        "  - receptive field가 큼 - 큰 영역으로 특징 파악\r\n",
        "  - stride =4 연산 복잡도 낮음\r\n",
        "> 2014 VGG에서 레이어를 깊게 하면 동일한 효과를 낸다는 것을 증명\r\n",
        "- 구현 할 수 있다.\r\n",
        "\r\n",
        "- overfitting 줄이기\r\n",
        "  - data augmentation 데이터 증강\r\n",
        "    - 차원에 비해 데이터가 부족한 경우 사용 \r\n",
        "  - dropout 사용\r\n",
        "    - 랜덤하게 제거 \r\n",
        "    - ensemble 효과\r\n",
        "\r\n",
        "- gradient descent\r\n",
        "  - weight decay\r\n",
        "  - optimizer : 상황별 학습방법 지정\r\n",
        "    - momentum\r\n",
        "  - 초기값 선택 방법에 따라 학습에 영향을 줌\r\n",
        "    - Zero-mean Gaussian (sd=0.01)\r\n",
        "\r\n",
        "### ZF-net\r\n",
        "### Visualizing and Understanding Convolutional Networks\r\n",
        "- **어떻게, 왜 성능이 잘 나오는지에 집중해서 시각화**\r\n",
        "> - 이전에 convolution 시각화 직접 구현했었음\r\n",
        "- AlexNet 그대로 가져와서 하이퍼 파라미터 튜닝만으로 성능 향상 시킴\r\n",
        "- **레이어 깊어지면서 선, 면과 같은 간단한 특징에서 점점 더 복잡한 feature들이 나옴**\r\n",
        "  - higher layer는 단순히 lower layer들의 가중합!\r\n",
        "-  다양한 실험 결과 11x11 , stride=4 에서 7x7 stride=2로 바꿈\r\n",
        "- deconvolution \r\n",
        "  - 나중에 다룰 예정\r\n",
        "- 하이퍼 파라미터의 중요성!\r\n",
        "- 복원하기 위해서 반대 과정을 거침\r\n",
        "- 참고 : https://keras.io/examples/vision/visualizing_what_convnets_learn/\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCgjizipuTBO"
      },
      "source": [
        "tf.keras.layers.Conv2D(groups) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZaJ6fgvsg_N"
      },
      "source": [
        "model.fit(optimizer= )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RFgNQhgQepE"
      },
      "source": [
        "tf.keras.applications.ResNet50V2( weights=\"imagenet\", include_top=False ) #이미 학습된 모델에서 Fcnn도 가져올지 결정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MajKIFr6Q0vE",
        "outputId": "ad97744e-3858-4662-9b8d-7f185056506f"
      },
      "source": [
        "model=tf.keras.applications.VGG16( )\r\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AskiFOzzQ5CI",
        "outputId": "9d27ef3b-6aea-4e24-b281-cbc4367a9cdd"
      },
      "source": [
        "model.layers[1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f0addbf08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4I5yi_fQ6fY",
        "outputId": "c8021397-2f19-4d49-dbce-ed5484095398"
      },
      "source": [
        "model.get_layer('block1_conv1') #이름을 지정"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f0addbf08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KynWRN5URPbw"
      },
      "source": [
        "학습 테크닉은 나중에 자세히 다룰 예정\r\n"
      ]
    }
  ]
}